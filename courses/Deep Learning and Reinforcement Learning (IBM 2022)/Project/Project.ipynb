{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Custom Object Detection with transfer learning with pre-trained YOLO-V4 model\n",
    "\n",
    "In this project we shall use the pre-trained Yolo (You only look once) V4 end-to-end one-stage object detection model (trained on MS COCO dataset) and train it to detect a custom object (Raccoon). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find your own Dataset & Dataset Description / Exploration\n",
    "\n",
    "* In this project we shall use the Raccoon Dataset: a Roboflow Public object Detection dataset, available here: https://public.roboflow.com/object-detection/raccoon\n",
    "\n",
    "* The dataset contains 196 raccoon images of size $416 \\times 416$, as shown in the next figure\n",
    "\n",
    "![](f1.png)\n",
    "\n",
    "* Roboflow allows to download the annotated images (with bounding boxes for the object Raccoon to be detected) in different formats, here we shall use darknet text format for the bounding box annotations, which can be used for both YOLO V3 and V4, as shown in the next figure.\n",
    "\n",
    "![](f2.png)\n",
    "\n",
    "* The following figure shows an image and the corresponding annotation text, denoting the position of the bounding box for the Raccoon object in the image. It will be used to firther train the YOLO-V4 model, to make it able to detect the custom object Raccoon.\n",
    "\n",
    "![](f3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the above annotation, the first two coordinates represent the center $(x, y)$ of the bounding box and the next two represent the width and height $(w, h)$ of the bounding box, respectively.\n",
    "\n",
    "* From the above representation, the bounding box left, top  $(x_1, y_1)$ and right bottom $(x_2, y_2)$ coordinates can be computed as follows:\n",
    "\n",
    "    $(x_1, y_1) = (416 \\times 0.3790 - \\frac{416 \\times 0.4904}{2}, 416 \\times 0.4796 - \\frac{416 \\times 0.7115}{2}) \\approx (56, 52)$ and \n",
    "    $(x_2, y_2) = (416 \\times 0.3790 + \\frac{416 \\times 0.4904}{2}, 416 \\times 0.4796 + \\frac{416 \\times 0.7115}{2}) \\approx (260, 348)$, \n",
    "\n",
    "   the corresponding bounding box can be drawn as shown in the next figure:\n",
    "\n",
    "![](f4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective & Outline\n",
    "\n",
    "* The original YOLO-v4 deep learning model being trained on MS COCO dataset, it can detect objects belonging to 80 different classes. Unfortunately, those 80 classes don't include Raccoon, hence, without explicit training the pre-trained model will not be able to identify the Raccoons from the image dataset.\n",
    "* Also, we have only 196 images of Raccoon, which is a pretty small number, so it's not feasible to train the YOLO-V4 model from scratch.\n",
    "* However, this is an ideal scenario to apply transfer learning. Since the task is same, i.e., object detection, we can always start with the pretrained weights on COCO dataset and then train the model on our images, starting from those initial weights.\n",
    "* Instead of training a model from scratch, let's use pre-trained YOLOv4 weights which have been trained up to 137 convolutional layers. Since the original model was trained on COCO dataset with 80 classes and we are interested in detection of an object of a single class (namely Raccoon), we need to modify the corresponding layers (in the conig file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning / feature engineering\n",
    "\n",
    "* Images are normalized to have value in between 0-1. Histogram equalization / contrast stretching can be used for image enhancement. Since this task involves object localization, data augmentation was not used, since it would then require the recomputation of the bounding box.\n",
    "* No other feature engineering technique was used, since the deep neural net contains so many convolution layers that automatically generates many different features, the earlier layers with simpler features and later layers more complicated features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taining with transfer learning - Configuration and Different hyperparameter settings \n",
    "\n",
    "* Google colab is used to train the model on GPU.\n",
    "\n",
    "* To start with we need to first clone the darknet source from the following git repository using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AlexeyAB/darknet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We need to change the Makefile to enable GPU and `opencv` and run `make` to create the darknet executable.\n",
    "* Next we need to download the pre-trained model yolov4.conv.137 and copy it to the right folder, using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P build/darknet/x64/ https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We need to copy the input image / annotation files to the right folders and provide the information for training data to the model, e.g., create a file build/darknet/x64/data/obj.data, that looks like the following:\n",
    "\n",
    "![](f6.png)\n",
    "\n",
    "Here the training and validation text files list the names of the training and validation set images, whereas backup represents the location for saving the model checkpoints while training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We need to create a configuration file (yolov4_train.cfg, e.g.,) for training the model on our images. A relevant portion of the config file (with few of the hyperparameters) to be used for training the YOLO-V4 model is shown below:\n",
    "\n",
    "![](f4.png)\n",
    "\n",
    "* Total number of images we have is 196, out of which 153 of them are used for training and the remaining are used for validation. \n",
    "\n",
    "* Since the number of training images is small, we keep the *batch size* hyperparamater (used 3 different values, namely, 16, 8 and 4) for training small too.\n",
    "\n",
    "* Notice that we need to chaneg the number of classes to $1$ (since we are interested to detect a single object here), as opposed to $80$ in the original config file and the number of features as $(1+5)\\times 3=18$, as shown in the next figure, a part of the config file, again.\n",
    "\n",
    "![](f5.png)\n",
    "\n",
    "* Number of batches for which the model is trained is 2000 (since it is recommended to be at least $2000 \\times num_classes$), the model checkpoints stored at batches 500, 1000 and 2000 respectively.\n",
    "\n",
    "* Now we can start training the model on our images, initializing it with the pretrained weights, using the following line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./darknet detector train build/darknet/x64/data/obj.data cfg/yolov4_train.cfg build/darknet/x64/yolov4.conv.137 -dont_show "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A few iterations of training are shown in the below figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](f7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It takes around ~2 hrs to finish 2000 batches and the final model weoghts are stored in a file (yolov4_train_final.weights) on the backup folder provide."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection and Testing / Prediction\n",
    "\n",
    "* Since the batch size 8 and subdivision size 2 resulted in higher accuracy (in terms of IOU), the corresponding model is selected as the best fit model.\n",
    "\n",
    "* The final model checkpoint saved can be used for prediction (with an unseen image test.jpg) with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./darknet detector test build/darknet/x64/data/obj.data cfg/yolov4_train.cfg build/darknet/x64/backup/yolov4_train_latest.weights -dont_show test.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Around ~500 test images with raccoons were used for custom object detection with the model trained. The following figures show the custom objects (Raccoons) detected with the model on a few unseen images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](f8.png)\n",
    "![](f9.png)\n",
    "![](f10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "* With a relatively few number of iterations and a small number of training images we could do a descent job for detecting custom objects using transfer learning.\n",
    "* The YOLO model's advantage being its speed (since a one-stage object detection model), starting with weights pretrained on MS-COCO for object detection followed by transfer learning one can detect custom objects with a few hours of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "We obtained a few false positives and false negatives with the model trained. To improve the performance of the model,\n",
    "\n",
    "* We can train the model for more batches (~10k)\n",
    "* Increase the input images with data augmentation + re-annotation\n",
    "* Tune many of the hyperparameters (momentum, decay etc.) of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. https://github.com/AlexeyAB/darknet/\n",
    "2. https://public.roboflow.com/object-detection/raccoon\n",
    "3. https://stackoverflow.com/questions/65204524/training-custom-object-detection-model-bin-bash-darknet-no-such-file-or-di/70562641#70562641\n",
    "4. https://www.youtube.com/watch?v=XC7CjbyTkAE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
