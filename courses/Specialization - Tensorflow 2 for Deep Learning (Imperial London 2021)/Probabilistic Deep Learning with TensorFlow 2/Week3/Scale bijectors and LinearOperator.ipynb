{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale bijectors and LinearOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reading is an introduction to scale bijectors, as well as the `LinearOperator` class, which can be used with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.1.0\n",
      "TFP version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"TFP version:\", tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "You have now seen how bijectors can be used to transform tensors and tensor spaces. Until now, you've only seen this in the scalar case, where the bijector acts on a single value. When the tensors you fed into the bijectors had multiple components, the bijector acted on each component individually by applying batch operations to scalar values. For probability distributions, this corresponds to a scalar event space.\n",
    "\n",
    "However, bijectors can also act on higher-dimensional space. You've seen, for example, the multivariate normal distribution, for which samples are tensors with more than one component. You'll need higher-dimensional bijectors to work with such distributions. In this reading, you'll see how bijectors can be used to generalise scale transformations to higher dimensions. You'll also see the `LinearOperator` class, which you can use to construct highly general scale bijectors. In this reading, you'll walk through the code, and we'll use figure examples to demonstrate these transformations.\n",
    "\n",
    "This reading contains many images, as this allows you to visualise how a space is transformed. For this reason, the examples are limited to two dimensions, since these allow easy plots. However, these ideas generalise naturally to higher dimensions. Let's start by creating a point that is randomly distributed across the unit square $[0, 1] \\times [0, 1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.38345742, 0.5265424 ], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the base distribution and a single sample\n",
    "\n",
    "uniform = tfd.Uniform(low=[0.0, 0.0], high=[1.0, 1.0], name='uniform2d')\n",
    "x = uniform.sample()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be applying linear transformations to this data. To get a feel for how these transformations work, we show ten example sample points, and plot them, as well as the domain of the underlying distribution:\n",
    "![](figures/x.png)\n",
    "\n",
    "Each of the ten points is hence represented by a two-dimensional vector. Let $\\mathbf{x} = [x_1, x_2]^T$ be one of these points. Then scale bijectors are linear transformations of $\\mathbf{x}$, which can be represented by a $2 \\times 2$ matrix $B$. The forward bijection to $\\mathbf{y} = [y_1, y_2]^T$ is\n",
    "\n",
    "$$\n",
    "\\mathbf{y} \n",
    "= \n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\ y_2\n",
    "\\end{bmatrix}\n",
    "= B \\mathbf{x}\n",
    "= \\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ x_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is important to remember: any two-dimensional scale bijector can be represented by a $2 \\times 2$ matrix. For this reason, we'll sometimes use the term \"matrix\" to refer to the bijector itself. You'll be seeing how these points and domain are transformed under different bijectors  in two dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `ScaleMatvec` bijectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `ScaleMatvecDiag` bijector\n",
    "\n",
    "We'll start with a simple scale bijector created using the `ScaleMatvecDiag` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ScaleMatvecDiag bijector\n",
    "\n",
    "bijector = tfb.ScaleMatvecDiag(scale_diag=[1.5, -0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which creates a bijector represented by the diagonal matrix\n",
    "$$ B = \n",
    "\\begin{bmatrix}\n",
    "1.5 & 0 \\\\\n",
    "0 & -0.5 \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "We can apply this to the data using `y = bijector(x)` for each of the ten points. This transforms the data as follows:\n",
    "![](figures/diag_1.png)\n",
    "You can see what happened here: the first coordinate is multiplied by 1.5 while the second is multipled by -0.5, flipping it through the horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0.57518613, -0.2632712 ], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the bijector to the sample point\n",
    "\n",
    "y = bijector(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `ScaleMatvecTriL` bijector\n",
    "\n",
    "In the previous example, the bijector matrix was diagonal, which essentially performs an independent scale operation on each of the two dimensions. The domain under the bijection remains rectangular. However, not all scale tarnsformations have to be like this. With a non-diagonal matrix, the domain will transform to a quadrilateral. One way to do this is by using the `tfb.ScaleMatvecTriL` class, which implements a bijection based on a lower-triangular matrix. For example, to implement the lower-triangular matrix\n",
    "$$ B = \n",
    "\\begin{bmatrix}\n",
    "-1 & 0 \\\\\n",
    "-1 & -1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "you can use the `tfb.ScaleMatvecTriL` bijector as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ScaleMatvecTriL bijector\n",
    "\n",
    "bijector = tfb.ScaleMatvecTriL(scale_tril=[[-1., 0.],\n",
    "                                           [-1., -1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.38345742, -0.90999985], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the bijector to the sample x\n",
    "\n",
    "y = bijector(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graphical overview of this change is:\n",
    "![](figures/lower_triangular.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse and composition\n",
    "\n",
    "Scale transformations always map the point $[0, 0]$ to itself and are only one particular class of bijectors. As you saw before, you can create more complicated bijections by composing one with another. This works just like you would expect. For example, you can compose a scale transformation with a shift to the left (by one unit) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scale and shift bijector\n",
    "\n",
    "scale_bijector = tfb.ScaleMatvecTriL(scale_tril=[[-1., 0.],\n",
    "                                                 [-1., -1.]])\n",
    "shift_bijector = tfb.Shift([-1., 0.])\n",
    "bijector = shift_bijector(scale_bijector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-1.3834574 , -0.90999985], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the bijector to the sample x\n",
    "\n",
    "y = bijector(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which has the expected result:\n",
    "![](figures/scale_and_shift.png)\n",
    "\n",
    "Furthermore, bijectors are always invertible (with just a few special cases, see e.g. [`Absolute Value`](https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/AbsoluteValue)), and these scale transformations are no exception. For example, running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the inverse transformation to the image of x\n",
    "\n",
    "bijector = tfb.ScaleMatvecTriL(scale_tril=[[-1., 0.],\n",
    "                                           [-1., -1.]])\n",
    "y = bijector.inverse(bijector(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recovers `x`:\n",
    "![](figures/inverse.png)\n",
    "so that the original and transformed data is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all y and x values are the same\n",
    "\n",
    "tf.reduce_all(y == x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `LinearOperator` class and `ScaleMatvecLinearOperator` bijector\n",
    "\n",
    "The examples you just saw used the `ScaleMatvecDiag` and `ScaleMatvecTriL` bijectors, whose transformations can be represented by diagonal and lower-triangular matrices respectively. These are convenient since it's easy to check whether such matrices are invertible (a requirement for a bijector). However, this comes at a cost of generality: there are acceptable bijectors whose matrices are not diagonal or lower-triangular. To construct these more general bijectors, you can use the `ScaleMatvecLinearOperator` class, which operates on instances of `tf.linalg.LinearOperator`.\n",
    "\n",
    "The `LinearOperator` is a class that allows the creation and manipulation of linear operators in TensorFlow. It's rare to call the class directly, but its subclasses represent many of the common linear operators. It's programmed in a way to have computational advantages when working with big linear operators, although we won't discuss these here. What matters now is that we can use these linear operators to define bijectors using the `ScaleMatvecLinearOperator` class. Let's see how this works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `LinearOperatorDiag` class\n",
    "\n",
    "First, let's use this framework to recreate our first bijector, represented by the diagonal matrix\n",
    "\n",
    "$$ B = \n",
    "\\begin{bmatrix}\n",
    "1.5 & 0 \\\\\n",
    "0 & -0.5 \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "You can do this using the `ScaleMatvecLinearOperator` as follows. First, we'll create the linear operator that represents the scale transformation using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = tf.linalg.LinearOperatorDiag(diag=[1.5, -0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `LinearOperatorDiag` is one of the subclasses of `LinearOperator`. As the name suggests, it implements a diagonal matrix. We then use this to create the bijector using the `tfb.ScaleMatvecLinearOperator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ScaleMatvecLinearOperator bijector\n",
    "\n",
    "bijector = tfb.ScaleMatvecLinearOperator(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bijector is the same as the first one above:\n",
    "![](figures/linear_operator_diag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0.57518613, -0.2632712 ], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the bijector to the sample x\n",
    "\n",
    "y = bijector(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `LinearOperatorFullMatrix` class\n",
    "\n",
    "We can also use this framework to create a bijector represented by a custom matrix. Suppose we have the matrix\n",
    "\n",
    "$$ B = \n",
    "\\begin{bmatrix}\n",
    "0.5 & 1.5 \\\\\n",
    "1.5 & 0.5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "which is neither diagonal nor lower-triangular. We can implement a bijector for it using the `ScaleMatvecLinearOperator` class by using another subclass of `LinearOperator`, namely the `LinearOperatorFullMatrix`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ScaleMatvecLinearOperator bijector\n",
    "\n",
    "B = [[0.5, 1.5],\n",
    "     [1.5, 0.5]]\n",
    "scale = tf.linalg.LinearOperatorFullMatrix(matrix=B)\n",
    "bijector = tfb.ScaleMatvecLinearOperator(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which leads to the following transformation:\n",
    "![](figures/linear_operator_full.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.98154235, 0.83845735], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the bijector to the sample x\n",
    "\n",
    "y = bijector(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch operations and broadcasting\n",
    "\n",
    "As you've seen before, it's important to be very careful with shapes in TensorFlow Probability. That's because there are three possible components to a shape: the event shape (dimensionality of the random variable), sample shape (dimensionality of the samples drawn) and batch shape (multiple distributions can be considered in one object). This subtlety is especially important for bijectors, but can be harnassed to make powerful, and very computationally efficient, transformations of spaces. Let's examine this a little bit in this section.\n",
    "\n",
    "In the previous examples, we applied a bijector to a two-dimensional data point $\\mathbf{x}$ to create a two-dimensional data point $\\mathbf{y}$. This was done using $\\mathbf{y} = B \\mathbf{x}$ where $B$ is the $2 \\times 2$ matrix that represents the scale bijector. This is simply matrix multiplication. To implement this, we created a tensor `x` with `x.shape == [2]` and a bijector using a matrix of shape `B.shape == [2, 2]`. This generalises straightforwardly to higher dimensions: if $\\mathbf{x}$ is $n$-dimensional, the bijection matrix must be of shape $n \\times n$ for some $n>0$. In this case, $\\mathbf{y}$ is $n$-dimensional.\n",
    "\n",
    "But what if you wanted to apply the same bijection to ten $\\mathbf{x}$ values at once? You can then arrange all these samples into a single tensor `x` with `x.shape == [10, 2]` and create a bijector as usual, with a matrix of shape `B.shape == [2, 2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[0.65328133, 0.5007515 ],\n",
       "       [0.7039211 , 0.6391289 ],\n",
       "       [0.17928898, 0.2344662 ],\n",
       "       [0.7448586 , 0.0904156 ],\n",
       "       [0.7366468 , 0.3043282 ],\n",
       "       [0.83564234, 0.19431233],\n",
       "       [0.52141714, 0.90067077],\n",
       "       [0.479604  , 0.3518784 ],\n",
       "       [0.24645162, 0.57086015],\n",
       "       [0.10066628, 0.17718911]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 10 samples from the uniform distribution\n",
    "\n",
    "x = uniform.sample(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.5,  0. ],\n",
       "       [ 0. , -0.5]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate the diagonal matrix transformation with LinearOperatorDiag\n",
    "\n",
    "scale = tf.linalg.LinearOperatorDiag(diag=[1.5, -0.5])\n",
    "scale.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ScaleMatvecLinearOperator bijector\n",
    "\n",
    "bijector = tfb.ScaleMatvecLinearOperator(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[ 0.979922  , -0.25037575],\n",
       "       [ 1.0558816 , -0.31956446],\n",
       "       [ 0.26893348, -0.1172331 ],\n",
       "       [ 1.1172879 , -0.0452078 ],\n",
       "       [ 1.1049702 , -0.1521641 ],\n",
       "       [ 1.2534635 , -0.09715617],\n",
       "       [ 0.7821257 , -0.45033538],\n",
       "       [ 0.719406  , -0.1759392 ],\n",
       "       [ 0.36967742, -0.28543007],\n",
       "       [ 0.15099943, -0.08859456]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the bijector to the 10 samples\n",
    "\n",
    "y = bijector(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the same plot we had before:\n",
    "![](figures/diag_1.png)\n",
    "For matrix multiplication to work, we need `B.shape[-1] == x.shape[-1]`, and the output tensor has last dimension `y.shape[-1] == B.shape[-2]`. For invertibility, we also need the matrix `B` to be square. Any dimensions except for the last one on `x` become sample/batch dimensions: the operation is broadcast across these dimensions as we are used to. It's probably easiest to understand through a table of values, where `s`, `b`, `m`, and `n` are positive integers and `m != n`:\n",
    "\n",
    "| `B.shape` | `x.shape` | `y.shape` |\n",
    "| ----- | ----- | ----- | \n",
    "| `(2, 2)` | `(2)` | `(2)` |\n",
    "| `(n, n)` | `(m)` | `ERROR` | \n",
    "| `(n, n)` | `(n)` | `(n)` | \n",
    "| `(n, n)` | `(s, n)` | `(s, n)` | \n",
    "| `(b, n, n)` | `(n)` | `(b, n)` |\n",
    "| `(b, n, n)` | `(b, n)` | `(b, n)` |\n",
    "| `(b, n, n)` | `(s, 1, n)` | `(s, b, n)` |  \n",
    "\n",
    "These rules and the ability to broadcast make batch operations easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily apply multiple bijectors. Suppose we want to apply both these bijectors:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "B_1 = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & -1 \\\\\n",
    "\\end{bmatrix}\n",
    "& \\qquad\n",
    "B_2 = \n",
    "\\begin{bmatrix}\n",
    "-1 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "\\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can do this using the batched bijector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batched ScaleMatvecLinearOperator bijector\n",
    "\n",
    "diag = tf.stack((tf.constant([1, -1.]), \n",
    "                 tf.constant([-1, 1.])))  # (2, 2)\n",
    "scale = tf.linalg.LinearOperatorDiag(diag=diag)  # (2, 2, 2)\n",
    "bijector = tfb.ScaleMatvecLinearOperator(scale=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can broadcast the samples across both bijectors in the batch, as well as broadcasting the bijectors across all samples. For this, we need to include a batch dimension in the samples Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a singleton batch dimension to x\n",
    "\n",
    "x = tf.expand_dims(x, axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the batched bijector to x\n",
    "\n",
    "y = bijector(x)\n",
    "y.shape  # (S, B, E) shape semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which gives two batches of forward values for each sample:\n",
    "![](figures/linear_operator_batch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this reading, you saw how to construct scale bijectors in two dimensions using the various `ScaleMatvec` classes. You also had a quick introduction to the general `LinearOperators` class and some of its subclasses. Finally, you saw how batching makes large computations clean and efficient. Be careful to keep track of the tensor shapes, as broadcasting and the difference between batch shapes and event shapes makes errors easy. Finally, note that these bijectors are still amenable to composition (via `Chain` or simply feeding one into another) and inversion, which retains the same syntax you're used to. Enjoy using this powerful tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading and resources\n",
    "\n",
    "* `ScaleMatvec` bijectors:\n",
    "  * https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/ScaleMatvecDiag\\n\",\n",
    "  * https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/ScaleMatvecLinearOperator\\n\",\n",
    "  * https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/ScaleMatvecLU\\n\",\n",
    "  * https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/ScaleMatvecTriL\\n\",\n",
    "* `LinearOperator` class (see also subclasses)\n",
    "  * https://www.tensorflow.org/api_docs/python/tf/linalg/LinearOperator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
