{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C4_W4_Lab_1_First_GAN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gjTm28G2tC6"
      },
      "source": [
        "# Ungraded Lab: First GAN with MNIST\n",
        "\n",
        "This lab will demonstrate the simple [Generative Adversarial Network (GAN)](https://arxiv.org/abs/1406.2661) you just saw in the lectures. This will be trained on the MNIST dataset and you will see how the network creates new images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY6UksTg2y2D"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H06EKcnhxLcM"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RmpKRoe3LDw"
      },
      "source": [
        "## Utilities\n",
        "\n",
        "We've provided a helper function to plot fake images. This will be used to visualize sample outputs from the GAN while it is being trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91DeiLbpxv5_"
      },
      "source": [
        "def plot_multiple_images(images, n_cols=None):\n",
        "    '''visualizes fake images'''\n",
        "    display.clear_output(wait=False)  \n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "\n",
        "    if images.shape[-1] == 1:\n",
        "        images = np.squeeze(images, axis=-1)\n",
        "\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    \n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuQqRvaE3YmK"
      },
      "source": [
        "## Download and Prepare the Dataset\n",
        "\n",
        "You will first load the MNIST dataset. For this exercise, you will just be using the training images so you might notice that we are not getting the `test` split nor the training labels below. You will also preprocess these by normalizing the pixel values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl5uWcOMxg8A"
      },
      "source": [
        "# load the train set of the MNIST dataset\n",
        "(X_train, _), _ = keras.datasets.mnist.load_data()\n",
        "\n",
        "# normalize pixel values\n",
        "X_train = X_train.astype(np.float32) / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9fsJW9IBuMG"
      },
      "source": [
        "You will create batches of the train images so it can be fed to the model while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK_wgrR0xAan"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS98MeLs3eu-"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "You will now create the two main parts of the GAN: \n",
        "* generator - creates the fake data\n",
        "* discriminator - determines if an image is fake or real\n",
        "\n",
        "You will stack Dense layers using the Sequential API to build these sub networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1vx-poh9BZp"
      },
      "source": [
        "### Generator\n",
        "\n",
        "The generator takes in random noise and uses it to create fake images. For that, this model will take in the shape of the random noise and will output an image with the same dimensions of the MNIST dataset (i.e. 28 x 28). \n",
        "\n",
        "[SELU](https://arxiv.org/abs/1706.02515) is found to be a good activation function for GANs and we use that in the first two dense networks. The final dense networks is activated with a sigmoid because we want to generate pixel values between 0 and 1. This is then reshaped to the dimensions of the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxnRLKojwkmG"
      },
      "source": [
        "# declare shape of the noise input\n",
        "random_normal_dimensions = 32\n",
        "\n",
        "# build the generator model\n",
        "generator = keras.models.Sequential([                                 \n",
        "    keras.layers.Dense(64, activation=\"selu\", input_shape=[random_normal_dimensions]),\n",
        "    keras.layers.Dense(128, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xs3vARf08Vx"
      },
      "source": [
        "Let's see a sample output of an untrained generator. As you expect, this will be just random points. After training, these will resemble digits from the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjk8x15gz_S2"
      },
      "source": [
        "# generate a batch of noise input (batch size = 16)\n",
        "test_noise = tf.random.normal([16, random_normal_dimensions])\n",
        "\n",
        "# feed the batch to the untrained generator\n",
        "test_image = generator(test_noise)\n",
        "\n",
        "# visualize sample output\n",
        "plot_multiple_images(test_image, n_cols=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMxfJA7R_7ls"
      },
      "source": [
        "### Discriminator\n",
        "\n",
        "The discriminator takes in the input (fake or real) images and determines if it is fake or not. Thus, the input shape will be that of the training images. This will be flattened so it can be fed to the dense networks and the final output is a value between 0 (fake) and 1 (real).\n",
        "\n",
        "Like the generator, we use SELU activation in the first two dense networks and we activate the final network with a sigmoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIn8IBVp9StA"
      },
      "source": [
        "# build the discriminator model\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(128, activation=\"selu\"),\n",
        "    keras.layers.Dense(64, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug1t6bkSAjPe"
      },
      "source": [
        "We can append these two models to build the GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6HnpPN59Te2"
      },
      "source": [
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf32S9uO3h6X"
      },
      "source": [
        "## Configure Training Parameters\n",
        "\n",
        "You will now prepare the models for training. You can measure the loss with `binary_crossentropy` because you're expecting labels to be either 0 (fake) or 1 (real)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lKpOq-Cw-r5"
      },
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVsJ5-VY3oCg"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "Next, you will define the training loop. This consists of two phases:\n",
        "\n",
        "* Phase 1 - trains the discriminator to distinguish between fake or real data\n",
        "* Phase 2 - trains the generator to generate images that will trick the discriminator\n",
        "\n",
        "At each epoch, you will display a sample gallery of images to see the fake images being created by the generator. The details of how these steps are carried out are shown in the code comments below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRt1ocLO2lx1"
      },
      "source": [
        "def train_gan(gan, dataset, random_normal_dimensions, n_epochs=50):\n",
        "    \"\"\" Defines the two-phase training loop of the GAN\n",
        "    Args:\n",
        "      gan -- the GAN model which has the generator and discriminator\n",
        "      dataset -- the training set of real images\n",
        "      random_normal_dimensions -- dimensionality of the input to the generator\n",
        "      n_epochs -- number of epochs\n",
        "    \"\"\"\n",
        "\n",
        "    # get the two sub networks from the GAN model\n",
        "    generator, discriminator = gan.layers\n",
        "\n",
        "    # start loop\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))       \n",
        "        for real_images in dataset:\n",
        "            # infer batch size from the training batch\n",
        "            batch_size = real_images.shape[0]\n",
        "\n",
        "            # Train the discriminator - PHASE 1\n",
        "            # Create the noise\n",
        "            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n",
        "            \n",
        "            # Use the noise to generate fake images\n",
        "            fake_images = generator(noise)\n",
        "            \n",
        "            # Create a list by concatenating the fake images with the real ones\n",
        "            mixed_images = tf.concat([fake_images, real_images], axis=0)\n",
        "            \n",
        "            # Create the labels for the discriminator\n",
        "            # 0 for the fake images\n",
        "            # 1 for the real images\n",
        "            discriminator_labels = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            \n",
        "            # Ensure that the discriminator is trainable\n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            # Use train_on_batch to train the discriminator with the mixed images and the discriminator labels\n",
        "            discriminator.train_on_batch(mixed_images, discriminator_labels)\n",
        "            \n",
        "            # Train the generator - PHASE 2\n",
        "            # create a batch of noise input to feed to the GAN\n",
        "            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n",
        "\n",
        "            # label all generated images to be \"real\"\n",
        "            generator_labels = tf.constant([[1.]] * batch_size)\n",
        "\n",
        "            # Freeze the discriminator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            # Train the GAN on the noise with the labels all set to be true\n",
        "            gan.train_on_batch(noise, generator_labels)\n",
        "\n",
        "        # plot the fake images used to train the discriminator\n",
        "        plot_multiple_images(fake_images, 8)                     \n",
        "        plt.show()      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADawDuEK3tfr"
      },
      "source": [
        "You can scroll through the output cell to see how the fake images improve per epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1lhjSj0xGL8"
      },
      "source": [
        "train_gan(gan, dataset, random_normal_dimensions, n_epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNaqSXTX5859"
      },
      "source": [
        "You might notice that as the training progresses, the model tends to be biased towards a subset of the numbers such as 1, 7, and 9. We'll see how to improve this in the next sections of the course."
      ]
    }
  ]
}