stop-words = "../data/lemur-stopwords.txt"
libsvm-modules = "../deps/libsvm-modules/"
prefix = "../data/"
function-words = "../data/function-words.txt"
punctuation = "../data/sentence-boundaries/sentence-punctuation.txt"
start-exceptions = "../data/sentence-boundaries/sentence-start-exceptions.txt"
end-exceptions = "../data/sentence-boundaries/sentence-end-exceptions.txt"
query-judgements = "../data/ceeaus-qrels.txt"

corpus-type = "line-corpus" 
dataset = "yelp" 
forward-index = "yelp-fwd" 
inverted-index = "yelp-inv"

[[analyzers]]
method = "ngram-word"
ngram = 1
	[[analyzers.filter]]
	type = "whitespace-tokenizer"
	[[analyzers.filter]]
	type = "lowercase"
	[[analyzers.filter]]
	type = "alpha"
	[[analyzers.filter]]
   	type = "length"
  	min = 2
  	max = 35
	[[analyzers.filter]]
	type = "list"
	file = "../data/lemur-stopwords.txt"
	[[analyzers.filter]]
	type = "porter2-stemmer"

[ranker]
method = "bm25"
k1 = 1.2
b = 0.75
k3 = 500

[classifier]
method = "naive-bayes"
path = "../deps/libsvm-modules/" # Path for SVM

[lda]
inference = "gibbs"
max-iters = 1000
alpha = 1.0
beta = 1.0
topics = 4
model-prefix = "lda-model"

[crf]
prefix = "crf"
treebank = "penn-treebank" # relative to data prefix
corpus = "wsj"
section-size = 99
train-sections = [0, 18]
dev-sections = [19, 21]
test-sections = [22, 24]

[sequence]
prefix = "../data/perceptron-tagger"
treebank = "penn-treebank" # relative to data prefix
corpus = "wsj"
section-size = 99
train-sections = [0, 18]
dev-sections = [19, 21]
test-sections = [22, 24]

[parser]
prefix = "parser"
treebank = "penn-treebank" # relative to data prefix
corpus = "wsj"
section-size = 99
train-sections = [2, 21]
dev-sections = [22, 22]
test-sections = [23, 23]
