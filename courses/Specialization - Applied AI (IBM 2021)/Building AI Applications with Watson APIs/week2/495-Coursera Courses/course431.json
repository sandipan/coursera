{"courseType":"v2.ondemand","description":"This course will teach you the \"magic\" of getting deep learning to work well. Rather than the deep learning process being a black box, you will understand what drives performance, and be able to more systematically get good results. You will also learn TensorFlow. \n\nAfter 3 weeks, you will: \n- Understand industry best-practices for building deep learning applications. \n- Be able to effectively use the common neural network \"tricks\", including initialization, L2 and dropout regularization, Batch normalization, gradient checking, \n- Be able to implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence. \n- Understand new best-practices for the deep learning era of how to set up train/dev/test sets and analyze bias/variance\n- Be able to implement a neural network in TensorFlow. \n\nThis is the second course of the Deep Learning Specialization.","id":"BZ5quSvBEee6gA5XksfBbg","slug":"deep-neural-network","instructorIds":["1244","24382163","20612763"],"specializations":[],"partnerIds":["475"],"name":"Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization"}